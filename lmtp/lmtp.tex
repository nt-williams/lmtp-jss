\documentclass[]{jss}

\usepackage[utf8]{inputenc}

\providecommand{\tightlist}{%
  \setlength{\itemsep}{0pt}\setlength{\parskip}{0pt}}

\author{
Nicholas Williams, MPH\\Weill Cornell Medicine \And Ivan Diaz,
PhD\\Weill Cornell Medicine
}
\title{\pkg{lmtp}: An \proglang{R} Package for Non-Parametric Causal
Effects Based on Modified Treatment Policies}

\Plainauthor{Nicholas Williams, MPH, Ivan Diaz, PhD}
\Plaintitle{lmtp: An R Package for Non-Parametric Causal Effects Based
on Modified Treatment Policies}
\Shorttitle{\pkg{lmtp}: Causal Effects Based on Modified Treatment
Policies}

\Abstract{
The majority of causal inference methods consider treatment effects
based on counterfactual outcomes where exposure is deterministically
established. When exposure is continuous, deterministic treatment
effects may be irrelevant and impossible to bring about. As a solution,
modified treatment policies offer a non-parametric alternative to
deterministic treatment effects that allow for the study of feasible
interventions and offer a safegaurd against positivity violations. The
\pkg{lmtp} package implements the estimators of
\citet{diazNonparametricCausalEffects2020a} for estimating causal
effects based on non-parametric modified treatment policies in \code{R}.
The provided methods can be applied to both point-treatment and
longitudinal settings, and can account for time-varying exposure,
covariates, and right censoring. Additionally, two of the provided
estimators can incorporate flexible data-adaptive algorithms for
estimation while maintaining valid statistical inference.
}

\Keywords{causal inference, non-parametric, modified treatment
policies, \proglang{R}}
\Plainkeywords{causal inference, non-parametric, modified treatment
policies, R}

%% publication information
%% \Volume{50}
%% \Issue{9}
%% \Month{June}
%% \Year{2012}
%% \Submitdate{}
%% \Acceptdate{2012-06-04}

\Address{
  Nicholas Williams, MPH\\
  Division of Biostatistics\\
  Department of Population Health Sciences\\ 
  Weill Cornell Medicine\\
  402 East 67th Street, New York, NY 10065\\
  E-mail: \email{niw4001@med.cornell.edu}\\
}

% Pandoc header

\usepackage{amsmath}

\begin{document}

\hypertarget{introduction}{%
\section{Introduction}\label{introduction}}

Most modern causal inference methods consider the effects of a exposure
on a population mean outcome under interventions that set the treatment
value deterministically. For example, the average treatment effect (ATE)
considers the hypothetical difference in a population mean outcome if a
dichotomous exposure was applied to all observations versus if it was applied
to none. In the case of a categorical or continuous exposure,
it is unlikely any policy could bring this about. Furthermore, the
estimation of causal effects requires the so called positivity
assumption which states that all observations have a greater than zero
chance of experiencing the exposure levels
\citep{rosenbaumCentralRolePropensity1983}. This assumption is often
violated when evaluating the effects of deterministic interventions and
is usually exacerbated with longitudinal data.

First introduced by \citet{haneuseEstimationEffectInterventions2013},
and building off work by \citet{munozPopulationInterventionCausal2012},
modified treatment policies (MTPs) are stochastic treatment regimes that
can be formulated to avoid violations of the positivity assumption.
\citet{diazNonparametricCausalEffects2020a} later extended MTPs to the
longitudinal setting with time-varying treatment, covariates, and
right-censoring of the outcome.

The package \pkg{lmtp} implements four methods for estimating the
effects of MTPs. Two of these estimators, a targeted minimum-loss based
estimator \citep{laanTargetedLearningCausal2011a, laanTargetedMaximumLikelihood2006}
and a sequentially doubly-robust estimator \citep{buckleyLinearRegressionCensored1979, fanCensoredRegressionLocal1994,
vanderlaanUnifiedCrossValidationMethodology2003, rotnitzkyDoublyRobustEstimation2006, rubinDoublyRobustCensoring2006, 
kennedyNonparametricMethodsDoubly2017}, are multiply-robust. In addition to MTPs, the package
naturally allows for estimation of the ATE, causal risk ratio, and
causal odds ratio and can thus be used for a variety of causal inference
problems. In this article we describe how \pkg{lmtp} can be used for
estimating the causal effects of MTPs and both static and dynamic
deterministic treatment effects. The package may be download from CRAN
at \url{cran.r-project.org/package=lmtp}.

\hypertarget{notation-and-modified-treatment-policies}{%
\section{Notation and modified treatment
policies}\label{notation-and-modified-treatment-policies}}

\hypertarget{data-structure}{%
\subsection{Data structure}\label{data-structure}}

In this article, we will use the notation of
\citet{diazNonparametricCausalEffects2020a} with slight modification.
Let \(i\) be the index of an observation from a data set with \(n\)
total units and \(t\) be the index of time for a total time of \(\tau\).
The observed data for observation \(Z_i\) may be denoted as

\begin{equation}
Z_i = (W, L_1, A_1, L_2, A_2, ..., L_{\tau}, A_{\tau}, Y_{\tau + 1}) 
\end{equation}

where \(W\) denotes baseline covariates, \(L_t\) denotes time-varying
covariates, \(A_t\) denotes a vector of exposure variables and \(Y\)
denotes an outcome at the end of study follow-up. We observe \(n\)
i.i.d. copies of \(Z\) with distribution \(\Prob\). We use \(A_t = a_t\) to
denote a realization of a random variable. If right-censoring
exists, \(A_t\) can be adapted so that \(A_t = (A_{1, t}, A_{2, t})\)
where \(A_{1, t}\) equals one if an observation is still in the study at
time \(t\) and zero otherwise, and \(A_{2, t}\) denotes the exposure at
time \(t\). We use an overbar to indicate the history of a variable up
until time \(t\). We
then use \(H_t = (\bar{L}_t, \bar{A}_{t-1})\) to denote the history of
all variables up until just before \(A_t\).

\hypertarget{modified-treatment-policies}{%
\subsection{Modified treatment
policies}\label{modified-treatment-policies}}

We will use the potential outcomes framework to define the causal effect
of interest using our established data structure. We consider
a hypothetical policy where \(\bar{A}\) is set to a
regime \(d\) defined as \(A^{d}_t = d_t(A_t, H^{d}_t)\),
where \(H^{d}_t = (\bar{L}_t, \bar{A}^{d}_t - 1)\), for a set of
user-given regimes \(d_t:t \in \{1, ..., \tau\}\). The defining
characteristic that makes regime \(d_t\) a modified treatment policy is
that it depends on the \emph{natural value} of \(\bar{A}_t\) and
\(\bar{L}_t\).

Formally, consider a longitudinal study with loss-to-follow-up. Let
\(A_t = (A_{1, t}, A_{2, t})\) where \(A_{1, t}\) equals one if an
observation is still in the study at time \(t\) and zero otherwise, and
\(A_{2, t}\) denote a continuous exposure at time \(t\) that can be
changed through some intervention. A modified treatment policy that
decreases \(A_t\) is then

\begin{equation}
d_t(a_t,h_t)=
\begin{cases}
(1, a_{2,t} - \delta_t) & \text{if } a_{2,t} > u_t(h_t) + \delta_t \\
(1, a_{2,t}) & \text{if } a_{2,t} \leq u_t(h_t) + \delta_t
\end{cases}
\end{equation}

where \(0 < \delta_t < u_t(h_t)\) is a user-defined value and \(A_t\) is
supported in the data. Notice that the hypothetical exposure after
intervention, \(A^{d}_t\) depends on the actually observed exposure,
\(A_t\). This is in contrast to a deterministic intervention where
\(A^{d}_t\) would be set to some arbitrary value with probability one.
If right-censoring did not exist in the data, the MTP \(d\) would
simplify to removing \(A_{1, t}\) from the MTP definition. In analogue
to \citet{diazNonparametricCausalEffects2020a}, in this article we will
focus on estimating the the causal effect of MTP \(d\) on outcome \(Y\),
using \pkg{lmtp}, through the causal parameter

\begin{equation}
\theta = \E\{Y(A^d)\}\text{,}
\end{equation}

where \(Y(A^d)\) is the potential outcome in a world, contrary to fact,
where \(\bar{A}\) was modified according to the MTP \(d\). When \(Y\) is
continuous, \(\theta\) is the mean population value of \(Y\) under MTP
\(d\); when \(Y\) is dichotomous, \(\theta\) is the population
proportion of event \(Y\) under MTP \(d\). Similarly, when \(Y\) is a
survival outcome, \(\theta\) is defined as the cumulative incidence of
\(Y\) under MTP \(d\).

\hypertarget{identification}{%
\subsection{Identification}\label{identification}}

Causal interpretation of \(\theta\) requires identifying an expression
of \(\theta\) as a function of the data generating distribution
\(\Prob\) using only the observed data \(Z\). A full review of these
identification assumptions is outside the scope of this article.
Briefly, the following standard assumptions must hold

\newtheorem{assumption}{Assumption}

\begin{assumption}[Consistency]
\(\bar{A} = \bar{a} \implies Y = Y(\bar{a})\) for all $\bar{a} \in \mathop{\mathrm{supp}}\bar{A}$ 
\end{assumption}
\begin{assumption}[Exchangeability]
If $(a_t, h_t) \in \mathop{\mathrm{supp}}\{A_t, H_t\}$ then $(d(a_t, h_t), h_t) \in \mathop{\mathrm{supp}}\{A_t, H_t\}$ for $t \in \{1, ..., \tau \}$
\end{assumption}
\begin{assumption}[Positivity]
$A_t \perp \!\!\! \perp Y(\bar{a}) | H_t$ for all $\bar{a} \in \mathop{\mathrm{supp}}\bar{A}$ and $t \in \{1, ..., \tau\}$
\end{assumption}

The consistency assumption states that the potential outcome for an
observation under their observed exposure is the value of the
outcome that we did actually observe. Assumption 2, the exchangeability
assumption, is often also referred to as the no-unmeasured confounding
assumption; it is satisfied if all common causes of the exposure and
outcome are measured and adjusted for. Of particular importance to this
article is the positivity assumption which states that the distribution of
the exposure under the MTP is supported in the data. Concretely, in a study with a
continuous exposure and loss-to-follow-up, the positivity assumption
states that if an observation with covariate history \(h_t\) and
exposure \(a_t\) who was not lost-to-follow-up at time \(t\) exists then
there is also an observation with covariate history \(h_t\) who was not
lost-to-follow-up at time \(t\) but whose exposure was observed as
\(d(a_t, h_t)\) that also exists. The strength of MTPs is that they may
be formulated to avoid violations of the positivity assumption,
which is often an issue when working with continuous exposures.

\hypertarget{estimating-modified-treatment-policy-effects}{%
\section{Estimating modified treatment policy
effects}\label{estimating-modified-treatment-policy-effects}}

\hypertarget{estimation-methods}{%
\subsection{Estimation methods}\label{estimation-methods}}

The \pkg{lmtp} package implements four estimation methods: a targeted
minimum-loss based estimator (TMLE), a sequential doubly-robust
estimator (SDR), an estimator based on the parametric G-formula, and an inverse
probability weighted (IPW) estimator. We will only describe the use of
TMLE, \code{lmtp_tmle}, and SDR, \code{lmtp_sdr}, as
their use is strongly suggested over the others.

Targeted minimum-loss based estimation is a general framework for constructing
asymptotically linear estimators with an optimal bias-variance tradeoff 
of the target causal parameter (INSERT A CITATION FOR THIS). In general, 
TMLE is constructed from a factorization of the target parameter 
into an outcome regression and a treatment mechanism. Using the outcome regression, 
an initial estimate of the target parameter is constructed and then \textit{de-biased} 
by a fluctuation that depends on a function of the treatment mechanism. The sequential
doubly-robust estimator is based on a unbiased transformation of the efficient influence
function of the target estimand. For a thorough discussion of TMLE and SDR, we
recommend the following articles (INSERT THESE ARTICLES).

Both TMLE and SDR are multiply-robust. Specifically, 
TMLE is considered \(\tau + 1\)-multiply robust while SDR is
robust under \(2^{\tau}\)-configurations. EXPLAIN WHAT THIS MEANS. 

It is important to note that it is possible for the SDR to produce an estimate of \(\hat{\theta}\)
outside of the bounds of the parameter space. Taking into account that for a single time-point
the TMLE and SDR have equivalent robustness, we recommend use of TMLE for the case of a single time-point, 
while we recommend use of SDR for the longitudinal setting. All examples in this article will use
both estimators.

\hypertarget{required-data-structure}{%
\subsection{Required data structure}\label{required-data-structure}}

Data is passed to \pkg{lmtp} estimators through the \code{data}
argument, and should be in wide format with one column per variable per
time point under study (i.e., there should be one column for every
variable in \(Z\)). These columns do not have to be in any specific
order and the data set may contain variables that won't be used in
estimation. The names of treatment variables, censoring variables,
baseline covariates, and time-varying covariates are specified using the
\code{trt}, \code{cens}, \code{baseline}, and \code{time_vary} arguments
respectively. The \code{trt}, \code{cens}, and \code{baseline} arguments
accept character vectors and the \code{trt} and \code{cens} arguments
should be ordered according to the time-ordering of the data generating
mechanism. The \code{time_vary} argument accepts an unnamed list ordered
according to the time-ordering of the model with each index containing
the name of the time-varying covariates for the given time. The outcome
variable is specified through the \code{outcome} argument.

The provided estimators can work with dichotomous, continuous, or
survival outcomes. In the case of a dichotomous or continuous outcome,
only a single variable name should be passed to the \code{outcome}
argument. For survival outcomes, a vector containing the names of the
intermediate outcome and final outcome variables ordered according to
time should be passed to the \code{outcome} argument. Dichotomous and
survival outcomes should be coded using zero's and one's where one
indicates the occurrence of an event and zero otherwise. The
\code{outcome_type} argument should be set to \code{"continuous"} for
continuous outcomes and \code{"binomial"} for dichotomous and survival
outcomes. If missingness is present in the outcome variable, the
\code{cens} argument must be provided. Censoring indicators should be
coded using zero's and one's where one indicates an observation is
observed at the next time and zero indicates loss-to-follow-up. Once an
observation's censoring status is switched to zero it cannot change back
to one. Missing data before an observation is lost-to-follow-up is not
allowed.

The \code{k} argument controls a Markov assumption of the data. With
\code{k = Inf}, the entire history \(H_t\) will be used for estimation
at time \(t\) while \code{k = 0} will restrict the set of variables in
\(H_t\) used for estimation to time-varying covariates at time \(t - 1\). 
Baseline confounders are always included in estimation. The 
\code{create_node_list} function may be used to inspect how variables
will be used for estimation. It is specified with the same \code{trt},
\code{baseline}, \code{time_vary}, and \code{k} arguments as \pkg{lmtp}
estimators and is used internally to create a ``node list'' that encodes
which variables should be used at each time point of estimation. For
example, consider a study with the observed data structure

\begin{equation}
Z = (W_1, W_2, L_{1, 1}, L_{1, 2}, A_1, L_{2, 1}, L_{2, 2}, A_2, Y_3)
\end{equation}

We can translate this data structure to \proglang{R} with

\begin{CodeChunk}

\begin{CodeInput}
R> baseline <- c("W_1", "W_2")
R> trt <- c("A_1", "A_2")
R> time_vary <- list(c("L_11", "L_12"), 
R+                   c("L_21", "L_22"))
R> create_node_list(trt = trt, baseline = baseline, 
R+                  time_vary = time_vary, tau = 2)
\end{CodeInput}

\begin{CodeOutput}
$trt
$trt[[1]]
[1] "W_1"  "W_2"  "L_11" "L_12" "A_1" 

$trt[[2]]
[1] "W_1"  "W_2"  "L_11" "L_12" "L_21" "L_22" "A_1"  "A_2" 


$outcome
$outcome[[1]]
[1] "W_1"  "W_2"  "L_11" "L_12" "A_1" 

$outcome[[2]]
[1] "W_1"  "W_2"  "L_11" "L_12" "A_1"  "L_21" "L_22" "A_2" 
\end{CodeOutput}
\end{CodeChunk}

A list of lists is returned with the names of the variables in \(H_t\) to be used for estimation of
the outcome regression and the treatment mechanism at every time \(t\).
Notice that variables \(A_1\) and \(A_2\) are included for their own
estimation. The \pkg{lmtp} package recasts the density ratio nuisance
parameter estimation into a classification problem based on a \(2n\)
observations augmented data set where an indicator variable \(\Lambda\)
is used as a pseudo outcome
\citep{chengSemiparametricDensityEstimation2004, qinInferencesCaseControlSemiparametric1998}.
In the augmented data set, the data structure at time \(t\) is
redefined as

\begin{equation}
(H_{\lambda, i, t}, A_{\lambda, i, t}, \Lambda_{\lambda, i} : \lambda = 0, 1; i = 1, ..., n)
\end{equation}

where \(\Lambda_{\lambda, i} = \lambda_i\) indexes the duplicate values.
For all duplicated observations \(i \in \{1, ..., 2n\}\),
\(H_{\lambda, i, t}\) is the same. While, for \(i \in \{1, ..., n\}\)
duplicated observations \(A_{0, i, t}\) are the observed exposure values
and \(A_{1, i, t}\) for \(i \in \{n+1, ..., 2n\}\) are the exposure
values under the MTP \(d\), \(A^{d}_t\).

\hypertarget{creating-modified-treatment-policies}{%
\subsection{Creating modified treatment
policies}\label{creating-modified-treatment-policies}}

Treatment policies are specified using the \code{shift} argument, which
accepts a user-defined function that returns a vector of exposure values
modified according to the policy of interest. Shift functions should take two
arguments, the first for specifying a data set and the second for
specifying the current exposure variable. For example, a possible MTP
may increase exposure by 2 units if the natural exposure value was below
5 units and do nothing otherwise. A shift function for this MTP would
look like

\begin{CodeChunk}

\begin{CodeInput}
R> function(data, trt) {
R+  (data[[trt]] < 5)*(data[[trt]] + 2) + (data[[trt]] >= 5)*data[[trt]]
R+ }
\end{CodeInput}

\end{CodeChunk}

This framework is flexible and allows for specifying complex treatment
regimes that can also depend on time and covariates. In the case of a
binary exposure, two shift functions are installed with
the package: \code{static_binary_on} which sets \(A_{i, t} = 1\), and
\code{static_binary_off} which sets \(A_{i, t} = 0\).

\hypertarget{the-estimation-engine}{%
\subsection{The estimation engine}\label{the-estimation-engine}}

An attractive property of multiply-robust estimators is that they can
incorporate flexible machine-learning algorithms for the estimation of
nuisance parameters while remaining \(\sqrt{n}\)-consistent. The super
learner algorithm is an ensemble learner than incorporates a set of
candidate models through a weighted convex-combination based on
cross-validation \citep{laanSuperLearner2007}. Asymptotically, this
weighted combination of models, called the meta-learner, will outperform
any single one of its components.

Access to the super learner is provided by the \pkg{sl3} package \citep{coyleSl3}. Analysts must create \pkg{sl3} learner stacks which
are then included in \code{lmtp_tmle} and \code{lmtp_sdr} calls with the \code{lrnrs_trt} and
\code{lrnrs_outcome} arguments. The outcome variable type should guide
users on selecting the appropriate candidate learners for use with the
\code{lrnrs_outcome} argument. Regardless of whether an exposure is
continuous, dichotomous, or categorical, the exposure mechanism is
estimated using classification, users should thus only include candidate
learners capable of binary classification with the \code{lrnrs_trt}
argument.

Candidate learners that rely on cross-validation
for the tuning of hyper-parameters should support grouped data if used with \code{lrnrs_trt}. Because
estimation of the treatment mechanism relies on the augmented \(2n\) duplicated
data set, duplicated observations must be put into the same fold during sample-splitting. 

User's may install \pkg{sl3} from \url{https://github.com/tlverse/sl3}.
Because \pkg{sl3} is not available for installation from a standard
repository, it is not required to use \pkg{lmtp}. Instead, the \code{lrnrs_trt} and 
\code{lrnrs_outcomes} arguments can be set equal to
\code{NULL} and nuisance parameters will be estimated using a
generalized linear model (GLM) with the \code{glm} function from the
\pkg{stats} package (INSERT STATS PACKAGE CITATION).

\hypertarget{additional-arguments}{%
\subsection{Additional arguments}\label{additional-arguments}}

Sample-splitting and cross-fitting is used with all methods \citep{zhengCrossValidatedTargetedMinimumLossBased2011b, chernozhukovDoubleDebiasedMachine2018}, and the number
of folds can be set with the \code{folds} argument; the minimum number of allowed folds is two.
If data has a hierarchical structure, the \code{id} argument is used to indicate the name of a variable
in the data set indicating unique groups. These identifiers will be used for generation of cross-validation 
folds and will be accounted for in standard error calculations.

\hypertarget{contrasts}{%
\subsection{Contrasts}\label{contrasts}}

In addition to the MTP effect, researchers may be interested in a comparison of the MTP effect
and the outcome under the observed exposures, or other treatment policies. This is the role of the \code{lmtp_contrast}
function. Users may specify any number of objects returned by calls to \code{lmtp_tmle} or \code{lmtp_sdr} to 
be compared to a single a reference value or a single reference MTP, specified using the \code{ref} argument. 
Depending on the outcome type, contrasts may be either additive (\code{type = "additive"}), an odds ratio (\code{type = "or"}), 
or the relative risk (\code{type = "rr"})

\hypertarget{examples}{%
\subsection{Examples}\label{examples}}

\hypertarget{example-1-longitudinal-mtp-with-no-loss-to-follow-up}{%
\subsubsection{Example 1: Longitudinal MTP with no
loss-to-follow-up}\label{example-1-longitudinal-mtp-with-no-loss-to-follow-up}}

We have simulated data on \(n = 5000\) observations over a 5-month
period. Each observation has a continuous exposure (\code{A_1},
\code{A_2}, \code{A_3}, \code{A_4}) and covariate (\code{L_1},
\code{L_2}, \code{L_3}, \code{L_4}) recorded at months one through four
and a dichotomous outcome (\code{Y}) at month five. We assume no
loss-to-follow-up and no Markov property. This data set is installed
with the package and is stored in the object \code{sim_t4}.

For this example, we are interested in the effect of a longitudinal MTP
where at each month an observation's exposure decreases by one only if
their observed exposure wouldn't be less than one if modified. Our data
structure has no baseline confounders and we will use only GLMs for
estimation so the only objects we must specify are the treatment
variables, the time-varying covariates, the outcome variable, and the
MTP shift function.

\begin{CodeChunk}

\begin{CodeInput}
R> trt <- c("A_1", "A_2", "A_3", "A_4")
R> time_vary <- list(c("L_1"), c("L_2"), c("L_3"), c("L_4"))
R> y <- "Y"
R> shift <- function(data, trt) {
R+   (data[[trt]] - 1) * (data[[trt]] - 1 >= 1) + 
R+     data[[trt]] * (data[[trt]] - 1 < 1)
R+ }
R> lmtp_tmle(sim_t4, trt, y, time_vary = time_vary, shift = shift)
\end{CodeInput}

\begin{CodeOutput}
LMTP Estimator: TMLE
   Trt. Policy: (shift)

Population intervention effect
      Estimate: 0.2646
    Std. error: 0.019
        95% CI: (0.2274, 0.3019)
\end{CodeOutput}

\begin{CodeInput}
R> lmtp_sdr(sim_t4, trt, y, time_vary = time_vary, shift = shift)
\end{CodeInput}

\begin{CodeOutput}
LMTP Estimator: SDR
   Trt. Policy: (shift)

Population intervention effect
      Estimate: 0.2608
    Std. error: 0.021
        95% CI: (0.2196, 0.3019)
\end{CodeOutput}

\end{CodeChunk}

\hypertarget{example-2-longitudinal-mtp-right-censoring-and-the-super-learner}{%
\subsubsection{Example 2: Longitudinal MTP, right-censoring, and the
super
learner}\label{example-2-longitudinal-mtp-right-censoring-and-the-super-learner}}

For this
example, we have a simulated dataset of \(n = 1000\) observations. Data
was simulated for three time points with a continuous time-varying
exposure at times \(t \in \{1, 2\}\) (\code{A1}, \code{A2}), a
dichotomous time-varying covariate at times \(t \in \{1, 2\}\)
(\code{L1}, \code{L2}), and a dichotomous outcome (\code{Y}) at time
\(t = 3\). Loss-to-follow-up is present after time \(t = 1\) so the data set
contains censoring indicators (\code{C1}, \code{C2}). This data is
installed with the package and is stored in the object \code{sim_cens}.

Suppose we are interested in the additive effect of an MTP where exposure
is increased by 0.5 at every time point for all observations. Instead of using a linear model, 
we will estimate the outcome regression and treatment mechanism using a super learner 
composed of a GLM, a random forest \citep{wrightRanger}, 
and multivariate adaptive regression splines \citep{milborrowEarth}. 

\begin{CodeChunk}

\begin{CodeInput}
R> trt <- c("A1", "A2")
R> cen <- c("C1", "C2")
R> time_vary <- list(c("L1"), c("L2"))
R> y <- "Y"
R> mtp <- function(data, trt) {
R+   data[[trt]] + 0.5
R+ }
R> lrnrs <- make_learner_stack(Lrnr_glm,
R+                             Lrnr_ranger, 
R+                             Lrnr_earth)
R> tml <- lmtp_tmle(sim_cens, trt, y, time_vary = time_vary, 
R+                  cens = cen, shift = mtp, learners_trt = lrnrs, 
R+                  learners_outcome = lrnrs, folds = 3)
R> print(tml)
\end{CodeInput}

\begin{CodeOutput}
LMTP Estimator: TMLE
   Trt. Policy: (mtp)

Population intervention effect
      Estimate: 0.9011
    Std. error: 0.0094
        95% CI: (0.8826, 0.9196)
\end{CodeOutput}

\begin{CodeInput}
R> sdr <- lmtp_sdr(sim_cens, trt, y, time_vary = time_vary, 
R+                 cens = cen, shift = mtp, learners_trt = lrnrs, 
R+                 learners_outcome = lrnrs, folds = 3)
R> print(sdr)
\end{CodeInput}

\begin{CodeOutput}
LMTP Estimator: SDR
   Trt. Policy: (mtp)

Population intervention effect
      Estimate: 0.8995
    Std. error: 0.0095
        95% CI: (0.881, 0.918)
\end{CodeOutput}

\end{CodeChunk}

If loss-to-follow-up exists, we can estimate the population mean outcome 
under the observed exposures by specifying \code{shift = NULL}. This 
estimate can then be used as the reference value for calculating the additive
effect of the MTP compared to the observed exposures.

\begin{CodeChunk}

\begin{CodeInput}
R> tml_obs <- lmtp_tmle(sim_cens, trt, y, time_vary = time_vary, 
R+                      cens = cen, shift = NULL, learners_trt = lrnrs, 
R+                      learners_outcome = lrnrs, folds = 3)
R> lmtp_contrast(tml, ref = tml_obs)
\end{CodeInput}

\begin{CodeOutput}
  LMTP Contrast: additive
Null hypothesis: theta == 0

  theta shift   ref std.error conf.low conf.high p.value
1 0.104 0.901 0.797   0.00607   0.0918     0.116  <0.001
\end{CodeOutput}

\begin{CodeInput}
R> sdr_obs <- lmtp_sdr(sim_cens, trt, y, time_vary = time_vary, 
R+                     cens = cen, shift = NULL, learners_trt = lrnrs, 
R+                     learners_outcome = lrnrs, folds = 3)
R> lmtp_contrast(sdr, ref = sdr_obs)
\end{CodeInput}

\begin{CodeOutput}
  LMTP Contrast: additive
Null hypothesis: theta == 0

   theta shift ref std.error conf.low conf.high p.value
1 0.0998 0.899 0.8   0.00612   0.0878     0.112  <0.001
\end{CodeOutput}

\end{CodeChunk}

\hypertarget{example-3-survival-analysis-and-deterministic-effects}{%
\subsubsection{Example 3: Survival analysis and deterministic effects}\label{example-3-survival-analysis-and-deterministic-effects}}

The \pkg{lmtp} package may also be used to estimate deterministic causal effects, such as the causal relative risk.
Suppose we have data on \(n = 2000\) observations with a time-invariant binary exposure followed for a
period of seven days. We wish to estimate the causal relative risk of experiencing an event by day seven. This data is
installed with the package and is stored in the object \code{sim_point_surv}. 

\begin{CodeChunk}

\begin{CodeInput}
R> trt <- "trt"
R> baseline <- c("W1", "W2")
R> cens <- paste0("C.", 0:5)
R> y <- paste0("Y.", 1:6)
R> tml1 <- lmtp_tmle(sim_point_surv, trt, y, baseline, cens = cens, 
R+                   learners_trt = lrnrs, learners_outcome = lrnrs,
R+                   shift = static_binary_on, folds = 3)
R> tml0 <- lmtp_tmle(sim_point_surv, trt, y, baseline, cens = cens, 
R+                   learners_trt = lrnrs, learners_outcome = lrnrs,
R+                   shift = static_binary_off, folds = 3)
R> lmtp_contrast(tml1, ref = tml0, type = "rr")
\end{CodeInput}

\begin{CodeOutput}
  LMTP Contrast: relative risk
Null hypothesis: theta == 1

  theta shift   ref std.error conf.low conf.high p.value
1  1.22 0.812 0.665    0.0341     1.14      1.31  <0.001
\end{CodeOutput}

\begin{CodeInput}
R> sdr1 <- lmtp_sdr(sim_point_surv, trt, y, baseline, cens = cens, 
R+                 learners_trt = lrnrs, learners_outcome = lrnrs,
R+                 shift = static_binary_on, folds = 3)
R> sdr0 <- lmtp_sdr(sim_point_surv, trt, y, baseline, cens = cens, 
R+                 learners_trt = lrnrs, learners_outcome = lrnrs,
R+                 shift = static_binary_off, folds = 3)
R> lmtp_contrast(sdr1, ref = sdr0, type = "rr")
\end{CodeInput}

\begin{CodeOutput}
  LMTP Contrast: relative risk
Null hypothesis: theta == 1

  theta shift   ref std.error conf.low conf.high p.value
1  1.21 0.809 0.667    0.0338     1.14       1.3  <0.001
\end{CodeOutput}

\end{CodeChunk}

\hypertarget{extra-features}{%
\subsection{Extra features}\label{extra-features}}

Computation time can rapidly increase with many time points and when using the super learner. As a solution, \pkg{lmtp} 
can utilize parallel processing provided by the \pkg{future} package \citep{future}. In addition, 
\pkg{lmtp} is compatible with the \pkg{progressr} package \citep{progressr} for producing progress bars by wrapping estimator calls in
\code{with_progress}. For users familiar with the \pkg{broom} package \citep{broom}, \pkg{lmtp} contains a \code{tidy} method. 

\hypertarget{reference-manual}{%
\section{Reference Manual}\label{reference-manual}}

\subsection[lmtp_tmle and lmtp_sdr]{\code{lmtp\_tmle} and \code{lmtp\_sdr}}

\subsubsection{Arguments}

\begin{itemize}

  \item \code{data}: A data frame in wide format. 
  \item \code{trt}: A vector containing the column names of the treatment variables ordered by time.
  \item \code{outcome}: The column name of the outcome variable. In the case of time-to-event 
  analysis, a vector containing the column names of the intermediate outcome variables and
  the final outcome variable ordered by time. Only numeric values are allowed. If
  the outcome type is binary, data should be coded as zeroes and ones.
  \item \code{baseline}: An optional vector containing the columns names of baseline covariates
  to be included for adjustment at every time-point.
  \item \code{time_vary}: A list the same length as the number of time-points under observation.
  The list should be ordered following the time ordering of the model.
  Each index of the list should be a vector containing the column names of the time-varying covariates
  at that time-point. 
  \item \code{cens}: An optional vector, the same length as \code{time_vary}, containing
  the column names of censoring indicators. Must be provided if there is missingness in the outcome or
  if a time-to-event analysis.
  \item \code{shift}: A two argument function that specifies how treatment variables should be shifted.
  \item \code{k}: An integer controlling the Markov property of the data generating mechanism. If \code{k = Inf}
  (default) the history \(H_t\) will contain all previous time-point variables. If \code{k = 0} the history will
  only contain baseline variables and time-varying covariates at \(t - 1\).
  \item \code{outcome_type}: The outcome variable type. Valid options are \code{"continuous"} and \code{"binomial"}.
  \item \code{id}: An optional column name containing cluster-level identifiers.
  \item \code{bounds}: An optional vector of length two containing the upper and lower bounds
  for a continuous outcome. If \code{NULL} the bounds will be taken as the minimum and maximum
   of the observed data; ignored if \code{outcome_type = "binomial"}
  \item \code{learners_outcome}: An optional \pkg{sl3} learner stack to be used for estimation
  of the outcome regression. If \code{NULL}, estimation will default to using a generalized linear model.
  \item \code{learners_trt}: An optional \pkg{sl3} learner stack to be used for estimation
  of the treatment mechanism. If \code{NULL}, estimation will default to using a generalized linear model.
  \item \code{folds}: The number of folds to be used for cross-fitting. The minimum number of allowed folds is two.
  \item \code{bound}: Determines that maximum and minimum values (scaled) predictions will be
  bounded to. The default is \code{1e-5}, bounding predictions between \(1\times10^{-5}\) and \(0.9999\).
  
\end{itemize}

\subsubsection{Returns}

Objects returned from calls to \code{lmtp_tmle} or \code{lmtp_sdr} will contain:

\begin{itemize}

  \item \code{estimator}: The estimator used, either TMLE or SDR.
  \item \code{theta}: The estimated population MTP effect.
  \item \code{standard_error}: The estimated, influence function based, standard error of
  the MTP effect.
  \item \code{low}: The lower bound of the 95\% confidence interval of the MTP effect.
  \item \code{high}: The lower bound of the 95\% confidence interval of the MTP effect.
  \item \code{eif}: The estimated, uncentered, influence function.
  \item \code{shift}: The shift function specified with the \code{shift} argument.
  \item \code{outcome_reg}: An \(n \times \tau + 1\) matrix contained the outcome regression
  predictions. The mean of the first column is used for calculating \code{theta}.
  \item \code{density_ratios}: An \(n \times \tau\) matrix containing the estimated density
  ratios from estimation of the treatment mechanism.
  \item \code{weights_m}: A list the same length as the \code{folds} argument containing the
  super learner ensemble weights at each time-point for each fold of the outcome regression.
  \item \code{weights_r}: A list the same length as the \code{folds} argument containing the
  super learner ensemble weights at each time-point for each fold of the treatment mechanism
  estimation.
  \item \code{outcome_type}: The outcome variable type.
  
\end{itemize}

\subsection[lmtp_contrast]{\code{lmtp\_contrast}}

\subsubsection{Arguments}

\begin{itemize}

  \item \code{...}: One or more objects returned from calls to \code{lmtp_tmle} or \code{lmtp_sdr}.
  \item \code{ref}: Either a scalar reference value or another object returned from a call
  to \code{lmtp_tmle} or \code{lmtp_sdr}. \code{ref} will be compared to all other objects
  specified in the \code{...} argument.
  \item \code{type}: The contrast of interest. Valid options are \code{"additive"} (default)
  for the additive effect, \code{"rr"} for the relative risk, and \code{"or"} for the odds
  ratio. \code{"rr"} and \code{"or"} are only allowed when the outcome is dichotomous.
  
\end{itemize}

\subsubsection{Returns}

Objects returned from calls to \code{lmtp_contrast} will be a list containing:

\begin{itemize}

  \item \code{type}: The contrast type specified with the \code{type} argument.
  \item \code{null}: The null hypothesis.
  \item \code{vals}: A data frame with the number of rows equal to the number
  of objects specified in the \code{...} argument. The data frame will contain
  columns for the contrast estimate (\code{"theta"}), standard error (\code{std.error}),
  and 95\% confidence interval lower (\code{"conf.low"}) and upper (\code{"conf.high"}) bounds.
  \item \code{eifs}: The estimated, uncentered, influence functions of the contrast estimates.
  
\end{itemize}

\subsection[create_node_list]{\code{create\_node\_list}}

\subsubsection{Arguments}

\begin{itemize}

  \item \code{trt}: A vector containing the names of the treatment variables ordered by time.
  \item \code{tau}: An integer specifying the maximum time-point of the data generating mechanism.
  \item \code{time_vary}: A list the same length as the number of time-points under observation.
  The list should be ordered following the time ordering of the model.
  Each index of the list should be a vector containing the names of the time-varying covariates
  at that time-point. 
  \item \code{baseline}: An optional vector containing the names of baseline covariates
  to be included for adjustment at every time-point.
  \item \code{k}: An integer controlling the Markov property of the data generating mechanism. If \code{k = Inf}
  (default) the history \(H_t\) will contain all previous time-point variables. If \code{k = 0} the history will
  only contain baseline variables and time-varying covariates at \(t - 1\).
  
\end{itemize}

\subsubsection{Returns}

A list of length two. Each index of the list will contain a list of length \(\tau\) with
each index being a vector of the column names to be used for estimation at the corresponding
time-point of either the outcome regression or treatment mechanism.

\renewcommand\refname{References}
\bibliography{lmtp.bib}

\end{document}
